{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 可视化计算图\n",
    "\n",
    "本例可视化mnist手写字识别的计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 加载库文件\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# 定义参数\n",
    "INPUT_NODE = 784\n",
    "LAYER1_NODE = 500\n",
    "OUTPUT_NODE = 10\n",
    "\n",
    "BATCH_SIZE = 32              # batch的大小\n",
    "LEARNING_RATE_BASE = 0.8     # 基础学习率\n",
    "LEARNING_RATE_DECAY = 0.99   # 学习率的衰减系数\n",
    "LEARNING_DECAY_STEPS = 50    # 循环一次数据集的轮数\n",
    "REGULARIZATION_RATE = 0.0001 # 正则化系数\n",
    "TRAINING_STEPS = 3000        # 训练的步数\n",
    "MOVING_AVERAGE_DECAY = 0.99  # 动量系数\n",
    "\n",
    "LOG_PATH = \"../../../../other/test.log\"\n",
    "\n",
    "global_step = tf.Variable(0, trainable=False, name=\"global_step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../datasets/MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ../../../datasets/MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../../../datasets/MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../../datasets/MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 获取数据集\n",
    "mnist = input_data.read_data_sets(\"../../../datasets/MNIST_data\", one_hot=True)\n",
    "\n",
    "# 计算LEARING_DECAY_STEP\n",
    "LEARNING_DECAY_STEPS = mnist.train.num_examples/BATCH_SIZE\n",
    "\n",
    "# 1.输入层\n",
    "with tf.name_scope(\"Input\"):\n",
    "    x = tf.placeholder(tf.float32, [None, INPUT_NODE], name=\"x-input\")\n",
    "    y_ = tf.placeholder(tf.float32, [None, OUTPUT_NODE], name=\"y-input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2.隐含层\n",
    "with tf.name_scope(\"Layer1\"):\n",
    "    w1 = tf.Variable(tf.truncated_normal([INPUT_NODE, LAYER1_NODE]), name=\"w1\")\n",
    "    b1 = tf.Variable(tf.truncated_normal([LAYER1_NODE]), name=\"b1\")\n",
    "    before_activate1 = tf.add(tf.matmul(x, w1), b1, name=\"layer1_add\")\n",
    "    layer1 = tf.nn.leaky_relu(before_activate1, name=\"layer1_result\")\n",
    "    regularizer_w1 = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)(w1)\n",
    "    tf.add_to_collection(\"regularizer\", regularizer_w1)\n",
    "    \n",
    "    # 把相关参数添加进直方图\n",
    "    tf.summary.histogram(\"w1\", w1)\n",
    "    tf.summary.histogram(\"b1\", b1)\n",
    "    tf.summary.histogram(\"before_activate1\", before_activate1)\n",
    "    tf.summary.histogram(\"layer1\", layer1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 3.输出层\n",
    "with tf.name_scope(\"Output\"):\n",
    "    w2 = tf.Variable(tf.truncated_normal([LAYER1_NODE, OUTPUT_NODE]), name=\"w2\")\n",
    "    b2 = tf.Variable(tf.truncated_normal([OUTPUT_NODE]), name=\"b2\")\n",
    "    before_activate2 = tf.add(tf.matmul(layer1, w2), b2, name=\"output_add\")\n",
    "    regularizer_w2 = tf.contrib.layers.l2_regularizer(REGULARIZATION_RATE)(w2)\n",
    "    tf.add_to_collection(\"regularizer\", regularizer_w2)\n",
    "    \n",
    "    # 把相关参数添加进直方图\n",
    "    tf.summary.histogram(\"w2\", w2)\n",
    "    tf.summary.histogram(\"b2\", b2)\n",
    "    tf.summary.histogram(\"before_activate2\", before_activate2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 4.预测值\n",
    "with tf.name_scope(\"prediction\"):\n",
    "    output_result = tf.nn.softmax(before_activate2, name=\"prediction\")\n",
    "    prediction = tf.equal(tf.argmax(output_result), tf.argmax(y_))\n",
    "    accuracy = tf.reduce_mean(tf.cast(prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5. 申请动量操作\n",
    "with tf.name_scope(\"movingaverage\"):\n",
    "    # 申请动量\n",
    "    ema = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "    # 把一切可以进行训练的变量加入动量\n",
    "    maintain_average_op = ema.apply(tf.trainable_variables())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 5.损失函数\n",
    "with tf.name_scope(\"Loss\"):\n",
    "    # 计算交叉熵\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits_v2(labels=y_, logits=before_activate2, name=\"cross_entropy\")\n",
    "    # 计算交叉熵的平均值\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    # 计算交叉熵\n",
    "    regularizer_loss = tf.add_n(tf.get_collection(\"regularizer\"), name=\"add_regularizer_loss\")\n",
    "    # 计算总的算是函数\n",
    "    sum_loss = tf.add(cross_entropy, regularizer_loss, name=\"add_all_loss\")\n",
    "    \n",
    "    # 把损失函数添加进图示\n",
    "    tf.summary.scalar(\"sum_loss\", sum_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 6.优化空间\n",
    "with tf.name_scope(\"optimize\"):\n",
    "    # 定义可变学习率\n",
    "    update_learning = tf.train.exponential_decay(learning_rate=LEARNING_RATE_BASE,\n",
    "                                                decay_steps=50,\n",
    "                                                decay_rate=LEARNING_RATE_DECAY,\n",
    "                                                global_step=global_step,\n",
    "                                                name=\"learning\")\n",
    "    # 定义优化操作\n",
    "    optimize_op = tf.train.GradientDescentOptimizer(update_learning).minimize(sum_loss, global_step=global_step)\n",
    "    \n",
    "# 7. 定义依赖操作\n",
    "with tf.control_dependencies([optimize_op, maintain_average_op]):\n",
    "    main_op = tf.no_op(name=\"main_op\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword can't be an expression (<ipython-input-19-3acb969b9623>, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-19-3acb969b9623>\"\u001b[1;36m, line \u001b[1;32m4\u001b[0m\n\u001b[1;33m    gpu_options.allow_growth=True)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m keyword can't be an expression\n"
     ]
    }
   ],
   "source": [
    "# 配置会话参数\n",
    "config = tf.ConfigProto(allow_soft__placement=True, \n",
    "                        log_device_placement=True)\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# 定义 summary 的综合操作\n",
    "summary_merge = tf.summary.merge_all()\n",
    "\n",
    "# 7. 进行训练和预测\n",
    "with tf.Session(config=config) as sess:\n",
    "    # 定义写日志FileWriter\n",
    "    FileWriter = tf.summary.FileWriter(LOG_PATH, sess.graph)\n",
    "    \n",
    "    # 变量初始化\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    # 迭代过程\n",
    "    for i in range(TRAINING_STEPS):\n",
    "        # 获取batch数据\n",
    "        xs, ys = mnist.train_next_batch(batch_size=batch_size)\n",
    "        tf.summary.image(\"image\", tensor=xs, max_outputs=BATCH_SIZE)\n",
    "        \n",
    "        # 每100次保存运行时的信息\n",
    "        if i % 100 == 0:\n",
    "            # 配置需要记录的信息种类\n",
    "            run_options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE)\n",
    "            \n",
    "            # 建立记录信息的protocol\n",
    "            run_metadata = tf.RunMetadata()\n",
    "            \n",
    "            # 将配置信息和记录运行信息的protocol传入运行的过程，\n",
    "            # 从而记录运行时每一个节点的时间、空间开销信息\n",
    "            _, loss, step, merge_all = sess.run([main_op, loss, global_step, summary_merge], \n",
    "                                     feed_dict={x:xs, y_:ys},\n",
    "                                     options=run_options,\n",
    "                                     run_metadata=run_metadata)\n",
    "            # 将节点在运行时的信息写入日志文件\n",
    "            FileWriter.add_run_metadata(run_metadata=run_metadata,\n",
    "                                        tag=(\"step%3d\" % i),\n",
    "                                        global_step=i)\n",
    "            # 将 summary 数据写入日志中\n",
    "            FileWriter.add_summary(merge_all, i)\n",
    "            \n",
    "            # 打印运行的信息\n",
    "            printf(\"After steps(%d) loss%g.\" % (step, loss))\n",
    "            \n",
    "        else:\n",
    "            # 运行计算图\n",
    "            _, loss, step, merge_all= sess.run([main_op, sum_loss, global_step, summary_merge], feed_dict={x: xs, y_:ys})\n",
    "            # 将 summary 数据写入日志中\n",
    "            FileWriter.add_summary(merge_all, i)\n",
    "        \n",
    "    # 关闭日志\n",
    "    FileWriter.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
