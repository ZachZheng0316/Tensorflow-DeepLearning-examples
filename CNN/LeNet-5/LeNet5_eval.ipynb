{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载库文件\n",
    "import time\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import LeNet5_infernece\n",
    "import LeNet5_train\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 每10s加载一次最新模型\n",
    "EVAL_INTERVAL_SECS = 10 # 加载的实践间隔\n",
    "BATCH = 5000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST_data\\train-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data\\train-labels-idx1-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data\\t10k-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'true' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-88f889d33f60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-88f889d33f60>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(argv)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[0mmnist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../datasets/MNIST_data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m     \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'__main__'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-6-88f889d33f60>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(mnist)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[1;31m# 每个EVAL_INTERVAL_SECS秒调用一次计算正确率的过程以检测训练过程中正确率的变化\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m         \u001b[1;32mwhile\u001b[0m \u001b[0mtrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSession\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0msess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m                 \u001b[1;31m# 获取数据\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'true' is not defined"
     ]
    }
   ],
   "source": [
    "# 定义评估函数\n",
    "def evaluate(mnist):\n",
    "    with tf.Graph().as_default() as g:\n",
    "        # 定义输入输出的格式和验证样本集\n",
    "        x = tf.placeholder(tf.float32, \n",
    "                           shape =[BATCH, \n",
    "                                   LeNet5_infernece.IMAGE_SIZE,\n",
    "                                   LeNet5_infernece.IMAGE_SIZE,\n",
    "                                   LeNet5_infernece.NUM_CHANNELS],\n",
    "                           name='x-input')\n",
    "        y_ = tf.placeholder(tf.float32, [BATCH, LeNet5_infernece.OUTPUT_NODE], name='y-input')\n",
    "        \n",
    "        \n",
    "        # 计算前向传播结果、计算准确率、计算精度\n",
    "        y = LeNet5_infernece.inference(x, False, None)\n",
    "        correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        \n",
    "        \n",
    "        # 构建滑动平均类\n",
    "        # 通过变量重命名的方式加载模型，这样在前向传播的过程中就不需要调用滑动平均类来获取平均值了\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(LeNet5_train.MOVING_AVERAGE_DECAY)\n",
    "        variable_to_restore = variable_averages.variables_to_restore()\n",
    "        saver = tf.train.Saver(variable_to_restore)\n",
    "        \n",
    "        \n",
    "        # 每个EVAL_INTERVAL_SECS秒调用一次计算正确率的过程以检测训练过程中正确率的变化\n",
    "        while True:\n",
    "            with tf.Session() as sess:\n",
    "                # 获取数据\n",
    "                # 加载全部的验证数据\n",
    "                xs = mnist.validation.images[0:BATCH]\n",
    "                ys = mnist.validation.labels[0:BATCH]\n",
    "        \n",
    "                # 调整xs的结构\n",
    "                reshape_xs = np.reshape(xs, (BATCH,\n",
    "                                             LeNet5_infernece.IMAGE_SIZE,\n",
    "                                             LeNet5_infernece.IMAGE_SIZE,\n",
    "                                             LeNet5_infernece.NUM_CHANNELS))\n",
    "                \n",
    "                # tf.train.get_checkpoint_state函数会通过checkpoint文件自动找到目录中最新的文件模型\n",
    "                ckpt = tf.train.get_checkpoint_state(LeNet5_train.MODEL_SAVE_PATH)\n",
    "                if ckpt and ckpt.model_checkpoint_path:\n",
    "                    # 加载模型\n",
    "                    saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "                    \n",
    "                    # 通过文件名得到模型保存时迭代的轮数\n",
    "                    global_step = ckpt.model_checkpoint_path.split('/')[-1].split('-')[-1]\n",
    "                    accuracy_score = sess.run(accuracy, feed_dict={x:reshape_xs, y_:ys})\n",
    "                    print(\"After %s training steps, validation accuracy =%g\" % (global_step, accuracy_score))\n",
    "                else:\n",
    "                    print(\"No Checkpoint file found\")\n",
    "                    time.sleep(EVAL_INTERVAL_SECS)\n",
    "                \n",
    "                time.sleep(EVAL_INTERVAL_SECS)\n",
    "            break;\n",
    "                \n",
    "# 主程序\n",
    "def main(argv=None):\n",
    "    mnist = input_data.read_data_sets('../datasets/MNIST_data', one_hot=True)\n",
    "    evaluate(mnist)\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
