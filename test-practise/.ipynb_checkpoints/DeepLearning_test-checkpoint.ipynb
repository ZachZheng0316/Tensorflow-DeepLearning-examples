{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 指数衰减函数的用法\n",
    "\n",
    "假设损失函数 $y = x^2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# 定义参数\n",
    "learning_rate = 0.1 # 基础学习率\n",
    "decay_rate = 0.9    # 基础衰减率\n",
    "decay_steps = 50     # 衰减步长\n",
    "\n",
    "x = tf.Variable(5, name=\"src-x\")\n",
    "\n",
    "# 定义迭代步长\n",
    "global_step = tf.Variable(0, trainable=False, name=\"global_step\")\n",
    "\n",
    "# 变量更新操作\n",
    "assign_op = tf.assign(global_step, global_step+1)\n",
    "\n",
    "# 定义衰减学习率\n",
    "update_learning_true = tf.train.exponential_decay(learning_rate=learning_rate,\n",
    "                                            decay_steps=decay_steps,\n",
    "                                            decay_rate=decay_rate,\n",
    "                                            global_step=global_step,\n",
    "                                            staircase=True,\n",
    "                                            name=\"true_decay_learning\")\n",
    "update_learning_false = tf.train.exponential_decay(learning_rate=learning_rate,\n",
    "                                            decay_steps=decay_steps,\n",
    "                                            decay_rate=decay_rate,\n",
    "                                            global_step=global_step,\n",
    "                                            staircase=False,\n",
    "                                            name=\"false_decay_learning\")\n",
    "\n",
    "\n",
    "# 定义一个summary scalar buffer\n",
    "summary_scalar_true = tf.summary.scalar(\"learning/true\", update_learning_true)\n",
    "summary_scalar_false = tf.summary.scalar(\"learning/false\", update_learning_false)\n",
    "\n",
    "# 定义一个 summary merge 操作\n",
    "summary_merge = tf.summary.merge_all()\n",
    "    \n",
    "with tf.Session() as sess:\n",
    "    # 定义一个 summary writer\n",
    "    summary_writer = tf.summary.FileWriter(\"../../../other/test.log/\", sess.graph)\n",
    "    \n",
    "    # 变量初始化\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    # 进行迭代操作\n",
    "    for i in range(1000):\n",
    "        # 更新变量操作\n",
    "        sess.run(assign_op)\n",
    "        \n",
    "        # 计算学习速率\n",
    "        summary_all = sess.run(summary_merge)\n",
    "        \n",
    "        # 把summary_all 写入 log 中\n",
    "        summary_writer.add_summary(summary_all, i)\n",
    "        \n",
    "    # 关闭 summary writer\n",
    "    summary_writer.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 正则化函数tf.contrib.layers.l1_regularizer/tf.contrib.layers.l2_regularizer的使用\n",
    "\n",
    "- 例子1：利用正则化函数验证一个矩阵\n",
    "- 例子2：在一个神经网络中，显示不使用正则化和使用正则化的差别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1:  10.0\n",
      "L2:  15.0\n",
      "L1_L2:  25.0\n"
     ]
    }
   ],
   "source": [
    "value = tf.constant([1.0, 2.0, 3.0, 4.0], name=\"const_value\")\n",
    "\n",
    "lamda = 1.0\n",
    "L1_regularize = tf.contrib.layers.l1_regularizer(lamda)(value)\n",
    "L2_regularize = tf.contrib.layers.l2_regularizer(lamda)(value)\n",
    "L1_L2_regularize = tf.contrib.layers.l1_l2_regularizer(lamda, lamda)(value)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    print(\"L1: \", L1_regularize.eval())\n",
    "    print(\"L2: \", L2_regularize.eval())\n",
    "    print(\"L1_L2: \", L1_L2_regularize.eval())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tf.contrib.leyers.fully_connected函数的用法\n",
    "# 构建一个全连接层\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "def dense_batch_relu(x, phase, scope):\n",
    "    with tf.variable_scope(scope):\n",
    "        h1 = tf.contrib.layers.fully_connected(\n",
    "            inputs=x, \n",
    "            num_outputs=100, \n",
    "            activation_fn=None, \n",
    "            scope=\"dense\")\n",
    "        h2 = tf.contrib.layers.batch_norm(\n",
    "            inputs=h1, \n",
    "            center=True, \n",
    "            scale=True, \n",
    "            is_training=phase, \n",
    "            scope=\"bn\")\n",
    "        return tf.nn.relu(h2, 'relu')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
