{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载库文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义必要的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 节点参数\n",
    "INPUT_NODE = 784\n",
    "LAYER1_NODE = 291\n",
    "LAYER2_NODE = 97\n",
    "LAYER3_NODE = 33\n",
    "OUTPUT_NODE = 10\n",
    "\n",
    "# 训练集参数\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 动量参数\n",
    "MOVING_AVERAGE_DECAY = 0.99 # 动量比例\n",
    "\n",
    "# 正则化参数\n",
    "REGULARELIZATION_RATE = 0.01 # 正则化率\n",
    "\n",
    "# 学习率参数\n",
    "LEARNING_RATE_BASE = 0.1 # 初始化学习率\n",
    "LEARNING_RATE_DECAY = 0.99 # 学习衰减率\n",
    "\n",
    "# 优化参数\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "TRAING_STEPS = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义前向传播函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(input_tensor, avg_class, weigth1, bias1, weight2, bias2, weight3, bias3, weight4, bias4):\n",
    "    # 如果不含滑动平均类\n",
    "    if avg_class == None:\n",
    "        # 计算第一层激活值\n",
    "        layer1 = tf.nn.leaky_relu(tf.matmul(input_tensor, weigth1) + bias1)\n",
    "        # 计算第二层激活值\n",
    "        layer2 = tf.nn.leaky_relu(tf.matmul(layer1, weight2) + bias2)\n",
    "        # 计算第三次\n",
    "        layer3 = tf.nn.leaky_relu(tf.matmul(layer2, weight3) + bias3)\n",
    "        # 计算第四层值，没有激活函数\n",
    "        return tf.matmul(layer3, weight4) + bias4\n",
    "        \n",
    "    # 如果含滑动平均类\n",
    "    else:\n",
    "        # 计算第一层激活值\n",
    "        layer1 = tf.nn.leaky_relu(tf.matmul(input_tensor, avg_class.average(weigth1)) + avg_class.average(bias1))\n",
    "        # 计算第二层激活值\n",
    "        layer2 = tf.nn.leaky_relu(tf.matmul(layer1, avg_class.average(weight2)) + avg_class.average(bias2))\n",
    "        # 计算第三次\n",
    "        layer3 = tf.nn.leaky_relu(tf.matmul(layer2, avg_class.average(weight3)) + avg_class.average(bias3))\n",
    "        # 计算第四层值，没有激活函数\n",
    "        return tf.matmul(layer3, avg_class.average(weight4)) + avg_class.average(bias4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(mnist):\n",
    "    # 构建输入输出接口\n",
    "    xs = tf.placeholder(tf.float32, shape=[None, INPUT_NODE], name=\"x-input\")\n",
    "    ys = tf.placeholder(tf.float32, shape=[None, OUTPUT_NODE], name=\"y-input\")\n",
    "    \n",
    "    # 构建权重\n",
    "    w1 = tf.Variable(tf.random_normal(shape=[INPUT_NODE, LAYER1_NODE], stddev=0.1))\n",
    "    b1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))\n",
    "    w2 = tf.Variable(tf.random_normal(shape=[LAYER1_NODE, LAYER2_NODE], stddev=0.1))\n",
    "    b2 = tf.Variable(tf.constant(0.1, shape=[LAYER2_NODE]))\n",
    "    w3 = tf.Variable(tf.random_normal(shape=[LAYER2_NODE, LAYER3_NODE], stddev=0.1))\n",
    "    b3 = tf.Variable(tf.constant(0.1, shape=[LAYER3_NODE]))\n",
    "    w4 = tf.Variable(tf.random_normal(shape=[LAYER3_NODE, OUTPUT_NODE], stddev=0.1))\n",
    "    b4 = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE]))\n",
    "    \n",
    "    # 定义滑动平均类\n",
    "    variable_average = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "    variable_average_op = variable_average.apply(tf.trainable_variables())\n",
    "    \n",
    "    # 计算前向传播:不带滑动平均类\n",
    "    y_pre = inference(xs, None, w1, b1, w2, b2, w3, b3, w4, b4)\n",
    "    \n",
    "    # 计算前向传播结果:带有滑动平均类\n",
    "    average_y = inference(xs, variable_average, w1, b1, w2, b2, w3, b3, w4, b4)\n",
    "    \n",
    "    # 计算交叉熵\n",
    "    predict_label = tf.argmax(ys, 1)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_pre,\n",
    "                                                                  labels=predict_label)\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    # 正则化\n",
    "    regularier = tf.contrib.layers.l2_regularizer(REGULARELIZATION_RATE)\n",
    "    regularization = regularier(w1) + regularier(w2) + regularier(w3) + regularier(w4)\n",
    "    loss = cross_entropy_mean + regularization\n",
    "    \n",
    "    # 设置指数衰减的学习率\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        LEARNING_RATE_BASE,\n",
    "        global_step,\n",
    "        mnist.train.num_examples / BATCH_SIZE,\n",
    "        LEARNING_RATE_DECAY,\n",
    "        staircase=True)\n",
    "    \n",
    "    # 优化损失函数\n",
    "    train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    # 定义依赖关系\n",
    "    with tf.control_dependencies([train_op, variable_average_op]):\n",
    "        train_op = tf.no_op(name=\"train\")\n",
    "        \n",
    "    # 计算正确率\n",
    "    correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(ys, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # 初始化会话，并开始训练\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        # 变量初始化\n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        # 获取交叉验证集和测试数据集\n",
    "        validate_feed = {xs: mnist.validation.images, ys: mnist.validation.labels}\n",
    "        test_feed = {xs: mnist.test.images, ys: mnist.test.labels}\n",
    "        \n",
    "        # 循环训练神经网络\n",
    "        for i in range(TRAING_STEPS):\n",
    "            if i % 1000 == 0:\n",
    "                validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "                print(\"After %d training step(s), validation accuracy using average model is %g\" % (i, validate_acc))\n",
    "    \n",
    "            xbatch, ybatch = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op, feed_dict={xs: xbatch, ys: ybatch})\n",
    "            \n",
    "        test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
    "        print(\"After %d training step(s), test accuracy using average model is %g\" % (TRAING_STEPS, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 程序主入口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../datasets/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../../datasets/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../../datasets/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../../datasets/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Tensor(\"truediv:0\", shape=(), dtype=float32) must be from the same graph as Tensor(\"ExponentialMovingAverage/decay:0\", shape=(), dtype=float32).",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-e2669bc3fae1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-13-e2669bc3fae1>\u001b[0m in \u001b[0;36mmain\u001b[1;34m(argv)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[0mmnist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_data_sets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"../../../datasets/MNIST_data/\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mone_hot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmnist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0m__name__\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;34m\"__main__\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-12-ac1eed420f12>\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(mnist)\u001b[0m\n\u001b[0;32m     17\u001b[0m     \u001b[1;31m# 定义滑动平均类\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[0mvariable_average\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mExponentialMovingAverage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMOVING_AVERAGE_DECAY\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglobal_step\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[0mvariable_average_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvariable_average\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;31m# 计算前向传播:不带滑动平均类\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\training\\moving_averages.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, var_list)\u001b[0m\n\u001b[0;32m    411\u001b[0m                                     name=\"num_updates\")\n\u001b[0;32m    412\u001b[0m         decay = math_ops.minimum(decay,\n\u001b[1;32m--> 413\u001b[1;33m                                  (1.0 + num_updates) / (10.0 + num_updates))\n\u001b[0m\u001b[0;32m    414\u001b[0m       \u001b[0mupdates\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    415\u001b[0m       \u001b[1;32mfor\u001b[0m \u001b[0mvar\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mvar_list\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mminimum\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   3021\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0min_graph_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3022\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[1;32m-> 3023\u001b[1;33m         \"Minimum\", x=x, y=y, name=name)\n\u001b[0m\u001b[0;32m   3024\u001b[0m     \u001b[0m_result\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3025\u001b[0m     \u001b[0m_inputs_flat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_op\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[1;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[0;32m    348\u001b[0m       \u001b[1;31m# Need to flatten all the arguments into a list.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    349\u001b[0m       \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 350\u001b[1;33m       \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_graph_from_inputs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_Flatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    351\u001b[0m       \u001b[1;31m# pylint: enable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_get_graph_from_inputs\u001b[1;34m(op_input_list, graph)\u001b[0m\n\u001b[0;32m   5053\u001b[0m         \u001b[0mgraph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5054\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0moriginal_graph_element\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 5055\u001b[1;33m         \u001b[0m_assert_same_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_graph_element\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   5056\u001b[0m       \u001b[1;32melif\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   5057\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not from the passed-in graph.\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mgraph_element\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program Files (x86)\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_assert_same_graph\u001b[1;34m(original_item, item)\u001b[0m\n\u001b[0;32m   4989\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0moriginal_item\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mitem\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4990\u001b[0m     raise ValueError(\"%s must be from the same graph as %s.\" % (item,\n\u001b[1;32m-> 4991\u001b[1;33m                                                                 original_item))\n\u001b[0m\u001b[0;32m   4992\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4993\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Tensor(\"truediv:0\", shape=(), dtype=float32) must be from the same graph as Tensor(\"ExponentialMovingAverage/decay:0\", shape=(), dtype=float32)."
     ]
    }
   ],
   "source": [
    "def main(argv=None):\n",
    "    mnist = input_data.read_data_sets(\"../../../datasets/MNIST_data/\", one_hot=True)\n",
    "    train(mnist)\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
