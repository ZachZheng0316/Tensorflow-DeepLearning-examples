{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 加载库文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义必要的参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 节点参数\n",
    "INPUT_NODE = 784\n",
    "LAYER1_NODE = 291\n",
    "LAYER2_NODE = 97\n",
    "LAYER3_NODE = 33\n",
    "OUTPUT_NODE = 10\n",
    "\n",
    "# 训练集参数\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# 动量参数\n",
    "MOVING_AVERAGE_DECAY = 0.99 # 动量比例\n",
    "\n",
    "# 正则化参数\n",
    "REGULARELIZATION_RATE = 0.01 # 正则化率\n",
    "\n",
    "# 学习率参数\n",
    "LEARNING_RATE_BASE = 0.1 # 初始化学习率\n",
    "LEARNING_RATE_DECAY = 0.99 # 学习衰减率\n",
    "\n",
    "# 优化参数\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "TRAING_STEPS = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义前向传播函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(input_tensor, avg_class, weigth1, bias1, weight2, bias2, weight3, bias3, weight4, bias4):\n",
    "    # 如果不含滑动平均类\n",
    "    if avg_class == None:\n",
    "        # 计算第一层激活值\n",
    "        layer1 = tf.nn.leaky_relu(tf.matmul(input_tensor, weigth1) + bias1)\n",
    "        # 计算第二层激活值\n",
    "        layer2 = tf.nn.leaky_relu(tf.matmul(layer1, weight2) + bias2)\n",
    "        # 计算第三次\n",
    "        layer3 = tf.nn.leaky_relu(tf.matmul(layer2, weight3) + bias3)\n",
    "        # 计算第四层值，没有激活函数\n",
    "        return tf.matmul(layer3, weight4) + bias4\n",
    "        \n",
    "    # 如果含滑动平均类\n",
    "    else:\n",
    "        # 计算第一层激活值\n",
    "        layer1 = tf.nn.leaky_relu(tf.matmul(input_tensor, avg_class.average(weigth1)) + avg_class.average(bias1))\n",
    "        # 计算第二层激活值\n",
    "        layer2 = tf.nn.leaky_relu(tf.matmul(layer1, avg_class.average(weight2)) + avg_class.average(bias2))\n",
    "        # 计算第三次\n",
    "        layer3 = tf.nn.leaky_relu(tf.matmul(layer2, avg_class.average(weight3)) + avg_class.average(bias3))\n",
    "        # 计算第四层值，没有激活函数\n",
    "        return tf.matmul(layer3, avg_class.average(weight4)) + avg_class.average(bias4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 定义训练函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(mnist):\n",
    "    # 构建输入输出接口\n",
    "    xs = tf.placeholder(tf.float32, shape=[None, INPUT_NODE], name=\"x-input\")\n",
    "    ys = tf.placeholder(tf.float32, shape=[None, OUTPUT_NODE], name=\"y-input\")\n",
    "    \n",
    "    # 构建权重\n",
    "    w1 = tf.Variable(tf.random_normal(shape=[INPUT_NODE, LAYER1_NODE], stddev=0.1))\n",
    "    b1 = tf.Variable(tf.constant(0.1, shape=[LAYER1_NODE]))\n",
    "    w2 = tf.Variable(tf.random_normal(shape=[LAYER1_NODE, LAYER2_NODE], stddev=0.1))\n",
    "    b2 = tf.Variable(tf.constant(0.1, shape=[LAYER2_NODE]))\n",
    "    w3 = tf.Variable(tf.random_normal(shape=[LAYER2_NODE, LAYER3_NODE], stddev=0.1))\n",
    "    b3 = tf.Variable(tf.constant(0.1, shape=[LAYER3_NODE]))\n",
    "    w4 = tf.Variable(tf.random_normal(shape=[LAYER3_NODE, OUTPUT_NODE], stddev=0.1))\n",
    "    b4 = tf.Variable(tf.constant(0.1, shape=[OUTPUT_NODE]))\n",
    "    \n",
    "    # 定义滑动平均类\n",
    "    variable_average = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "    variable_average_op = variable_average.apply(tf.trainable_variables())\n",
    "    \n",
    "    # 计算前向传播:不带滑动平均类\n",
    "    y_pre = inference(xs, None, w1, b1, w2, b2, w3, b3, w4, b4)\n",
    "    \n",
    "    # 计算前向传播结果:带有滑动平均类\n",
    "    average_y = inference(xs, variable_average, w1, b1, w2, b2, w3, b3, w4, b4)\n",
    "    \n",
    "    # 计算交叉熵\n",
    "    predict_label = tf.argmax(ys, 1)\n",
    "    cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(logits=y_pre,\n",
    "                                                                  labels=predict_label)\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy)\n",
    "    \n",
    "    # 正则化\n",
    "    regularier = tf.contrib.layers.l2_regularizer(REGULARELIZATION_RATE)\n",
    "    regularization = regularier(w1) + regularier(w2) + regularier(w3) + regularier(w4)\n",
    "    loss = cross_entropy_mean + regularization\n",
    "    \n",
    "    # 设置指数衰减的学习率\n",
    "    learning_rate = tf.train.exponential_decay(\n",
    "        LEARNING_RATE_BASE,\n",
    "        global_step,\n",
    "        mnist.train.num_examples / BATCH_SIZE,\n",
    "        LEARNING_RATE_DECAY,\n",
    "        staircase=True)\n",
    "    \n",
    "    # 优化损失函数\n",
    "    train_op = tf.train.GradientDescentOptimizer(learning_rate).minimize(loss)\n",
    "    \n",
    "    # 定义依赖关系\n",
    "    with tf.control_dependencies([train_op, variable_average_op]):\n",
    "        train_op = tf.no_op(name=\"train\")\n",
    "        \n",
    "    # 计算正确率\n",
    "    correct_prediction = tf.equal(tf.argmax(average_y, 1), tf.argmax(ys, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "    \n",
    "    # 初始化会话，并开始训练\n",
    "    config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    config.gpu_options.allow_growth = True\n",
    "    with tf.Session(config=config) as sess:\n",
    "        # 变量初始化\n",
    "        tf.global_variables_initializer().run()\n",
    "        \n",
    "        # 获取交叉验证集和测试数据集\n",
    "        validate_feed = {xs: mnist.validation.images, ys: mnist.validation.labels}\n",
    "        test_feed = {xs: mnist.test.images, ys: mnist.test.labels}\n",
    "        \n",
    "        # 循环训练神经网络\n",
    "        for i in range(TRAING_STEPS):\n",
    "            if i % 1000 == 0:\n",
    "                validate_acc = sess.run(accuracy, feed_dict=validate_feed)\n",
    "                print(\"After %d training step(s), validation accuracy using average model is %g\" % (i, validate_acc))\n",
    "    \n",
    "            xbatch, ybatch = mnist.train.next_batch(BATCH_SIZE)\n",
    "            sess.run(train_op, feed_dict={xs: xbatch, ys: ybatch})\n",
    "            \n",
    "        test_acc = sess.run(accuracy, feed_dict=test_feed)\n",
    "        print(\"After %d training step(s), test accuracy using average model is %g\" % (TRAING_STEPS, test_acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 程序主入口"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../../../datasets/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../../../datasets/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../../../datasets/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../../../datasets/MNIST_data/t10k-labels-idx1-ubyte.gz\n",
      "After 0 training step(s), validation accuracy using average model is 0.1014\n",
      "After 1000 training step(s), validation accuracy using average model is 0.931\n",
      "After 2000 training step(s), validation accuracy using average model is 0.9394\n",
      "After 3000 training step(s), validation accuracy using average model is 0.9444\n",
      "After 4000 training step(s), validation accuracy using average model is 0.939\n",
      "After 5000 training step(s), validation accuracy using average model is 0.9314\n",
      "After 6000 training step(s), validation accuracy using average model is 0.9352\n",
      "After 7000 training step(s), validation accuracy using average model is 0.93\n",
      "After 8000 training step(s), validation accuracy using average model is 0.9398\n",
      "After 9000 training step(s), validation accuracy using average model is 0.9282\n",
      "After 10000 training step(s), validation accuracy using average model is 0.9484\n",
      "After 11000 training step(s), validation accuracy using average model is 0.949\n",
      "After 12000 training step(s), validation accuracy using average model is 0.9398\n",
      "After 13000 training step(s), validation accuracy using average model is 0.9456\n",
      "After 14000 training step(s), validation accuracy using average model is 0.9466\n",
      "After 15000 training step(s), validation accuracy using average model is 0.9458\n",
      "After 16000 training step(s), validation accuracy using average model is 0.9408\n",
      "After 17000 training step(s), validation accuracy using average model is 0.9494\n",
      "After 18000 training step(s), validation accuracy using average model is 0.9456\n",
      "After 19000 training step(s), validation accuracy using average model is 0.949\n",
      "After 20000 training step(s), validation accuracy using average model is 0.9406\n",
      "After 21000 training step(s), validation accuracy using average model is 0.9422\n",
      "After 22000 training step(s), validation accuracy using average model is 0.9438\n",
      "After 23000 training step(s), validation accuracy using average model is 0.9472\n",
      "After 24000 training step(s), validation accuracy using average model is 0.9432\n",
      "After 25000 training step(s), validation accuracy using average model is 0.9398\n",
      "After 26000 training step(s), validation accuracy using average model is 0.949\n",
      "After 27000 training step(s), validation accuracy using average model is 0.95\n",
      "After 28000 training step(s), validation accuracy using average model is 0.9532\n",
      "After 29000 training step(s), validation accuracy using average model is 0.9446\n",
      "After 30000 training step(s), validation accuracy using average model is 0.9496\n",
      "After 31000 training step(s), validation accuracy using average model is 0.9456\n",
      "After 32000 training step(s), validation accuracy using average model is 0.95\n",
      "After 33000 training step(s), validation accuracy using average model is 0.9418\n",
      "After 34000 training step(s), validation accuracy using average model is 0.9418\n",
      "After 35000 training step(s), validation accuracy using average model is 0.9492\n",
      "After 36000 training step(s), validation accuracy using average model is 0.9436\n",
      "After 37000 training step(s), validation accuracy using average model is 0.944\n",
      "After 38000 training step(s), validation accuracy using average model is 0.9324\n",
      "After 39000 training step(s), validation accuracy using average model is 0.9396\n",
      "After 40000 training step(s), validation accuracy using average model is 0.947\n",
      "After 41000 training step(s), validation accuracy using average model is 0.9418\n",
      "After 42000 training step(s), validation accuracy using average model is 0.9494\n",
      "After 43000 training step(s), validation accuracy using average model is 0.9452\n",
      "After 44000 training step(s), validation accuracy using average model is 0.9372\n",
      "After 45000 training step(s), validation accuracy using average model is 0.9476\n",
      "After 46000 training step(s), validation accuracy using average model is 0.9238\n",
      "After 47000 training step(s), validation accuracy using average model is 0.9428\n",
      "After 48000 training step(s), validation accuracy using average model is 0.941\n",
      "After 49000 training step(s), validation accuracy using average model is 0.951\n",
      "After 50000 training step(s), test accuracy using average model is 0.9377\n"
     ]
    }
   ],
   "source": [
    "def main(argv=None):\n",
    "    mnist = input_data.read_data_sets(\"../../../datasets/MNIST_data/\", one_hot=True)\n",
    "    train(mnist)\n",
    "    \n",
    "if __name__==\"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
