{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#迁移学习\" data-toc-modified-id=\"迁移学习-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>迁移学习</a></span></li><li><span><a href=\"#inception-v3模型相关参数\" data-toc-modified-id=\"inception-v3模型相关参数-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>inception-v3模型相关参数</a></span></li><li><span><a href=\"#新模型相关参数\" data-toc-modified-id=\"新模型相关参数-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>新模型相关参数</a></span></li><li><span><a href=\"#读取inception-v3模型\" data-toc-modified-id=\"读取inception-v3模型-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>读取inception-v3模型</a></span></li><li><span><a href=\"#产生特征向量\" data-toc-modified-id=\"产生特征向量-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>产生特征向量</a></span></li><li><span><a href=\"#把图片数据转化为特征向量并保存\" data-toc-modified-id=\"把图片数据转化为特征向量并保存-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>把图片数据转化为特征向量并保存</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 迁移学习"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob\n",
    "import os.path\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.platform import gfile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inception-v3模型相关参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 瓶颈层节点个数\n",
    "BOTTLENECK_TENSOR_SIZE = 2048\n",
    "\n",
    "# 图片输入张量所对应的名称\n",
    "JPEG_DATA_TENSOR_NAME = 'DecodeJpeg/contents:0'\n",
    "# Inception-v3瓶颈层结果的张量名称。在Inception-v3模型中，\n",
    "# 这个张量名称就是‘pool_3/_reshape:0’。\n",
    "BOTTLENECK_TENSOR_NAME = 'pool_3/_reshape:0'\n",
    "\n",
    "# 下载谷歌训练好的Inception-v3模型文件目录\n",
    "MODEL_DIR = '../../../datasets/inception_dec_2015'\n",
    "# 下载谷歌讯号的Inception-v3模型文件名\n",
    "MODEL_FILE = 'tensorflow_inception_graph.pb'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 新模型相关参数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 图片数据文件夹\n",
    "FLOWER_DIR = \"../../../datasets/flower_photos\"\n",
    "\n",
    "# 图片特征文件夹\n",
    "FEATURE_DIR = \"../../../datasets/flower_features\"\n",
    "\n",
    "\n",
    "# 划分数据集百分比\n",
    "VALIDATION_PERCENTAGE = 20 # 交叉验证集百分比\n",
    "TEST_PERCENTAGE = 10       # 测试集数据百分比"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 读取inception-v3模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_inception_v3():\n",
    "    # 加载模型\n",
    "    with gfile.FastGFile(os.path.join(MODEL_DIR, MODEL_FILE), 'rb') as f:\n",
    "        graph_def = tf.GraphDef()\n",
    "        graph_def.ParseFromString(f.read())\n",
    "        \n",
    "    # 加载需要的节点\n",
    "    bottleneck_tensor, jpeg_data_tensor = tf.import_graph_def(graph_def,return_elements=[BOTTLENECK_TENSOR_NAME, JPEG_DATA_TENSOR_NAME])\n",
    "    \n",
    "    # 返回节点\n",
    "    return bottleneck_tensor, jpeg_data_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 产生特征向量\n",
    "\n",
    "1. 取出文件夹中的每一张图片;\n",
    "2. 把每一张图片转化为特征向量;\n",
    "3. 把特征向量按比例存储到 training、validation 和 testing文件夹中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_features(sess, jpeg_data_tensor, bottleneck_tensor):\n",
    "    # 读取当前目录下的所有子目录\n",
    "    sub_dirs = [x[0] for x in os.walk(FLOWER_DIR)]\n",
    "    print(\"sub_dirs: \\n\", sub_dirs)\n",
    "    is_root_dir = True\n",
    "    \n",
    "    # 初始化各个标签\n",
    "    training_index = 0\n",
    "    validation_index = 0\n",
    "    testing_index = 0\n",
    "    current_label = 0\n",
    "    \n",
    "    # 读取所有的子目录\n",
    "    for sub_dir in sub_dirs:\n",
    "        if True == is_root_dir:\n",
    "            is_root_dir = False\n",
    "            continue\n",
    "            \n",
    "        # 获取一个子目录中所有的图片文件\n",
    "        extensions = ['jpg', 'jpeg']\n",
    "        file_list = []\n",
    "        dir_name = os.path.basename(sub_dir)\n",
    "        for extension in extensions:\n",
    "            file_glob = FLOWER_DIR + \"/\" + dir_name + \"/\" + \"*.\" + extension\n",
    "            file_list.extend(glob.glob(file_glob))\n",
    "        if not file_list:\n",
    "            continue\n",
    "        print(\"processing: \", dir_name)\n",
    "        print(\"image num: \", len(file_list))\n",
    "        \n",
    "        current_label += 1\n",
    "        image_index = 0\n",
    "        # 处理图片数据\n",
    "        for file_name in file_list:\n",
    "            # 获取每张图片数据\n",
    "            image_raw_data = tf.gfile.FastGFile(file_name, \"rb\").read()\n",
    "            \n",
    "            # 把每一张图片数据转化为对应的特征数据\n",
    "            image_feature = sess.run(bottleneck_tensor, feed_dict={jpeg_data_tensor:image_raw_data})\n",
    "            image_feature = np.squeeze(image_feature).tolist() # 把多维数据调整为向量\n",
    "            image_label = np.eye(5)[current_label-1].tolist()\n",
    "            \n",
    "            # 把image_feature和image_label转化为Example Protocol Buffer形式\n",
    "            float_feature = tf.train.Feature(float_list=tf.train.FloatList(value=image_feature))\n",
    "            float_label = tf.train.Feature(float_list=tf.train.FloatList(value=image_label))\n",
    "            feature = {\"image_feature\": float_feature, \"image_label\": float_label}\n",
    "            features = tf.train.Features(feature=feature)\n",
    "            example = tf.train.Example(features=features)\n",
    "            serialized = example.SerializeToString()\n",
    "            \n",
    "            # 随机划分数据\n",
    "            chance = np.random.randint(100)\n",
    "            if chance < VALIDATION_PERCENTAGE:\n",
    "                # 构建交叉验证集数据地址\n",
    "                file_name = (\"validation.tfrecords-%.5d\" % validation_index)\n",
    "                example_path = FEATURE_DIR + \"/\" + \"validation\" + \"/\" + file_name\n",
    "                validation_index += 1\n",
    "            elif chance < VALIDATION_PERCENTAGE + TEST_PERCENTAGE:\n",
    "                # 构建测试集数据地址\n",
    "                file_name = (\"testing.tfrecords-%.5d\" % testing_index)\n",
    "                example_path = FEATURE_DIR + \"/\" + \"testing\" + \"/\" + file_name\n",
    "                testing_index += 1\n",
    "            else:\n",
    "                # 构建训练集数据地址\n",
    "                file_name = (\"training.tfrecords-%.5d\" % training_index)\n",
    "                example_path = FEATURE_DIR + \"/\" + \"training\" + \"/\" + file_name\n",
    "                training_index += 1\n",
    "                \n",
    "            # 保存特征数据\n",
    "            writer = tf.python_io.TFRecordWriter(example_path)\n",
    "            writer.write(serialized)\n",
    "            writer.close()\n",
    "                \n",
    "            if image_index % 200 == 0:\n",
    "                print(image_index, \"images processed\")\n",
    "            image_index += 1\n",
    "            \n",
    "    # 返回结果\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 把图片数据转化为特征向量并保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sub_dirs: \n",
      " ['../../../datasets/flower_photos', '../../../datasets/flower_photos\\\\daisy', '../../../datasets/flower_photos\\\\dandelion', '../../../datasets/flower_photos\\\\roses', '../../../datasets/flower_photos\\\\sunflowers', '../../../datasets/flower_photos\\\\tulips']\n",
      "processing:  daisy\n",
      "image num:  633\n",
      "0 images processed\n",
      "200 images processed\n",
      "400 images processed\n",
      "600 images processed\n",
      "processing:  dandelion\n",
      "image num:  898\n",
      "0 images processed\n",
      "200 images processed\n",
      "400 images processed\n",
      "600 images processed\n",
      "800 images processed\n",
      "processing:  roses\n",
      "image num:  641\n",
      "0 images processed\n",
      "200 images processed\n",
      "400 images processed\n",
      "600 images processed\n",
      "processing:  sunflowers\n",
      "image num:  699\n",
      "0 images processed\n",
      "200 images processed\n",
      "400 images processed\n",
      "600 images processed\n",
      "processing:  tulips\n",
      "image num:  799\n",
      "0 images processed\n",
      "200 images processed\n",
      "400 images processed\n",
      "600 images processed\n"
     ]
    }
   ],
   "source": [
    "config = tf.ConfigProto(allow_soft_placement=True)\n",
    "config.gpu_options.allow_growth=True\n",
    "with tf.Session(config=config) as sess:\n",
    "    # 变量初始化\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    # 加载模型\n",
    "    bottleneck_tensor, jpeg_data_tensor = read_inception_v3()\n",
    "    \n",
    "    # 产生特征向量并保存\n",
    "    generate_features(sess, jpeg_data_tensor, bottleneck_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
