{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 原生LeNet5\n",
    "\n",
    "LeNet5 在当时的特点\n",
    "- 每个卷积层包含三个部分：卷积、池化和非线性激活函数\n",
    "- 使用卷积提取空间特征\n",
    "- 降采样(Subsample)的平均池化层(Average Pooling)\n",
    "- 双曲正切(Tanh)或S型(Sigmoid)的激活函数\n",
    "- MLP作为最后的分类器\n",
    "- 层与层之间的稀疏连接减少计算复杂度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LeNet5的结构\n",
    "\n",
    "- **input:** $32*32*1$ image\n",
    "- **C1:** conv$5*5@6$\n",
    "- **S2:** maxpool$2*2$ Sigmoid\n",
    "- **C3:** conv$5*5@16$\n",
    "- **S4:** maxpool$2*2$\n",
    "- **C5:** conv$5*5@120$\n",
    "- **F6:** 84 Node Sigmoid\n",
    "- **F7:** 10 Output \n",
    "\n",
    "LeNet5的输入图像为32*32的灰度图像，后面有三个卷积层，一个全连接层和一个高斯连接层。它的第一个卷积层C1包含6个卷积核，卷积核尺寸为5*5，即总共$(5*5+1)*6=156$个参数，括号中的1代表1个bias，后面是一个2*2的平均池化层S2用来进行降采样，再之后是一个Sigmoid激活函数用来进行非线性处理。而后是第二个卷积层C3，同样卷积核尺寸是5*5，这里使用了16个卷积核，对应16个Feature Map。需要注意的是，这里的16个Feature Map不是全部链接到前面的6个Feature Map的输出，有些只连接了其中的几个Feature Map，这样可以增加模型的多样性。下面的第二个池化层S4和第一个池化层S2一致，都是2*2的降采样。接下来的第三个卷积层C5有120个卷积核，卷积大小同样为5*5，因为输入图像的大小刚好也是5*5，因此成为了全连接，也可以算作全连接层。F6层是一个全连接层，拥有84个隐含节点，激活函数为Sigmoid。LeNet5最后一层由欧式径向基函数单元组成，它输出最后的分类结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 导入库文件\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../datasets/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting ../datasets/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 加载数据集\n",
    "mnist = input_data.read_data_sets(\"../datasets/MNIST_data/\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 构建默认的会话框\n",
    "sess = tf.InteractiveSession()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义权重函数\n",
    "# 我们需要给权重制造一些随机噪声来打破完全对称，比如截断的正太分布噪声，\n",
    "# 标准差设为0.1\n",
    "def weight_variable(shape):\n",
    "    initial = tf.truncated_normal(shape=shape, stddev=0.1)\n",
    "    return tf.Variable(initial)\n",
    "\n",
    "# 定义偏置\n",
    "# 因为使用Relu，为了避免死亡节点(dead neurons)，给偏置加一些小的正值\n",
    "def bias_variable(shape):\n",
    "    initial = tf.constant(0.1, shape=shape)\n",
    "    return tf.Variable(initial)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "卷积层、池化层也是接下来要重复使用的，因此也为他们分别定义创建函数。这里的tf.nn.conv2d是TensorFlow中的2维卷积函数，参数中x是输入，W是卷积参数，比如[5, 5, 1, 32]:前面两个数字代表卷积核的尺寸；第三个数字代表有多少个channel。因为我们只有灰度单色，所以是1，如果是彩色的RGB图片，这里应该是3.最后一个数字代表卷积核的数量，也就是这个卷积核会提取多少类的特征。Stride代表卷积模板移动的步长，都是1代表会不遗漏地划过图片的每一个点。Padding代表边界的处理方式，这里的SAME代表给边界加上Padding让卷积的输出和输入保持同样的SAME的尺寸。tf.nn.max_pool是TensorFlow中最大的池化函数，我们这里使用2*2的最大池化，即将一个2*2的像素降到1*1的像素。最大池化会保留原始像素块中灰度值最高的那一个像素，即保留显著的特征，因为希望整体上缩小图片尺寸，因此池化层的strides也设为横竖两个方向以2为步长。如果步长还是1，那么我们会得到一个尺寸不变的图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conv2d(x, W):\n",
    "    return tf.nn.conv2d(x, W, strides=[1, 1, 1, 1], padding='SAME')\n",
    "\n",
    "def max_pool_2x2(x):\n",
    "    return tf.nn.max_pool(x, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义输入接口和图片label\n",
    "# 因为卷积神经网络会利用空间结构信息，因此需要将1D的输出向量转化为2D的图片结构，\n",
    "# 即从1x784的形式转为原始的28*28的结构。\n",
    "# 尺寸为[-1, 28, 28, 1]:其中-1表示样本树林里不固定\n",
    "x = tf.placeholder(tf.float32, [None, 784])\n",
    "y_ = tf.placeholder(tf.float32, [None, 10])\n",
    "x_image = tf.reshape(x, [-1, 28, 28, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义第一个卷积层\n",
    "W_conv1 = weight_variable([5, 5, 1, 32])\n",
    "b_conv1 = bias_variable([32])\n",
    "h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "h_pool1 = max_pool_2x2(h_conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义第二个卷积层\n",
    "W_conv2 = weight_variable([5, 5, 32, 64])\n",
    "b_conv2 = bias_variable([64])\n",
    "h_conv2 = tf.nn.relu(conv2d(h_pool1, W_conv2) + b_conv2)\n",
    "h_pool2 = max_pool_2x2(h_conv2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "因为前面两次经历了两次步长为2*2的最大池化层，所有边长已经只有1/4了，图片尺寸由28*28变成了7*7，而第二个卷积层的卷积核数量为64，其输出的tensor尺寸即为7*7*64。我们使用tf.reshape函数对第二个卷积层的输出tensor进行变形，将其转成1D的向量。然后连接一个全连接层，隐含层节点为1024，并使用ReLU激活函数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W_fc1 = weight_variable([7*7*64, 1024])\n",
    "b_fc1 = bias_variable([1024])\n",
    "h_pool2_flat = tf.reshape(h_pool2, [-1, 7*7*64])\n",
    "h_fc1 = tf.nn.relu(tf.matmul(h_pool2_flat, W_fc1) + b_fc1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 为了减轻过拟合，下面使用一个Dropt层\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "h_fc1_drop = tf.nn.dropout(h_fc1, keep_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 最后我们将Dropout层的输出连接到一个Softmax层，得到最后的结果\n",
    "W_fc2 = weight_variable([1024, 10])\n",
    "b_fc2 = bias_variable([10])\n",
    "y_conv = tf.nn.softmax(tf.matmul(h_fc1_drop, W_fc2) + b_fc2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义损失函数\n",
    "cross_entropy = tf.reduce_mean(-tf.reduce_sum(y_ * tf.log(y_conv),\n",
    "                                             reduction_indices=[1]))\n",
    "train_step = tf.train.AdamOptimizer(1e-4).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定义评测节点\n",
    "correct_prediction = tf.equal(tf.argmax(y_conv, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 0, training accuracy 0.12\n",
      "Step 100, training accuracy 0.904\n",
      "Step 200, training accuracy 0.938\n",
      "Step 300, training accuracy 0.968\n",
      "Step 400, training accuracy 0.964\n",
      "Step 500, training accuracy 0.976\n",
      "Step 600, training accuracy 0.982\n",
      "Step 700, training accuracy 0.974\n",
      "Step 800, training accuracy 0.982\n",
      "Step 900, training accuracy 0.988\n",
      "Step 1000, training accuracy 0.99\n",
      "Step 1100, training accuracy 0.992\n",
      "Step 1200, training accuracy 0.994\n",
      "Step 1300, training accuracy 0.982\n",
      "Step 1400, training accuracy 0.986\n",
      "Step 1500, training accuracy 0.994\n",
      "Step 1600, training accuracy 0.996\n",
      "Step 1700, training accuracy 0.992\n",
      "Step 1800, training accuracy 0.994\n",
      "Step 1900, training accuracy 0.992\n",
      "Step 2000, training accuracy 1\n",
      "Step 2100, training accuracy 1\n",
      "Step 2200, training accuracy 0.992\n",
      "Step 2300, training accuracy 1\n",
      "Step 2400, training accuracy 0.992\n",
      "Step 2500, training accuracy 0.998\n",
      "Step 2600, training accuracy 0.992\n",
      "Step 2700, training accuracy 0.998\n",
      "Step 2800, training accuracy 0.998\n",
      "Step 2900, training accuracy 0.998\n"
     ]
    }
   ],
   "source": [
    "# 开始训练\n",
    "# 首先依然是初始化所有的参数\n",
    "# 设置训练时Dropout的keep_prob比率为0.5.\n",
    "# 然后使用大小为50的mini-batch，共进行20000次训练迭代，参与训练的样本量总共有100万\n",
    "# 其中每100次训练，我们会对准确率进行一次评测(评测时)keep_prob设为1，用以实时监测模型性能\n",
    "tf.global_variables_initializer().run()\n",
    "\n",
    "for i in range(3000):\n",
    "    batch = mnist.train.next_batch(500)\n",
    "    if i % 100 ==0:\n",
    "        train_accuracy = accuracy.eval(feed_dict={x: batch[0], y_:batch[1], \n",
    "                                                  keep_prob:1.0})\n",
    "        print(\"Step %d, training accuracy %g\" % (i, train_accuracy))\n",
    "    train_step.run(feed_dict={x: batch[0], y_:batch[1], keep_prob: 0.5})\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy 0.984\n"
     ]
    }
   ],
   "source": [
    "# 全部训练结束之后，我们在测试集上进行全面测试，得到整体的分类准确率\n",
    "# 一次性全部训练10000张图片，容易造成内存泄漏\n",
    "print(\"test accuracy %g\" % accuracy.eval(feed_dict={x: mnist.test.images[:3000], \n",
    "                                                    y_: mnist.test.labels[:3000],\n",
    "                                                   keep_prob: 1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
