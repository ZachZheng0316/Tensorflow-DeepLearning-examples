{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow计算模型--计算图"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 计算图的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow的程序一般分为两个阶段：构建计算图和执行计算图。\n",
    "在Tensorflow程序中，系统会自动维护一个默认的计算图，通过`tf.get_default_graph`函数可以获取默认的计算图"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "a = tf.constant([1.0, 2.0], name='a')\n",
    "b = tf.constant([2.0, 3.0], name='b')\n",
    "result = a + b\n",
    "\n",
    "# 通过a.graph可以查看张量所属的计算图。\n",
    "# 因为没有特意指定，所以这个计算图应该属于当前默认的计算图。\n",
    "# 所以的下面的操作应该位true\n",
    "print(a.graph is tf.get_default_graph())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "除了使用默认的计算图以外，TensorFlow支持通过`tf.Graph`函数来生成新的计算图。\n",
    "不同计算图上的张量和运算都不会共享。以下代码示意了在不同计算图上定义和使用变量。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "[1.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    # 在计算图g1上定义变量\"v\"，并设置值为0\n",
    "    v = tf.get_variable(\"v\", shape=[1], initializer=tf.zeros_initializer())\n",
    "    \n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    # 在计算图g2上定义变量\"v\"，并设置值为1\n",
    "    v = tf.get_variable(\"v\", shape=[1], initializer=tf.ones_initializer())\n",
    "    \n",
    "# 在计算图g1中读取变量\"v\"的取值\n",
    "with tf.Session(graph=g1) as sess:\n",
    "    # 变量初始化\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        # 在计算图g1中，变量\"v\"的取值应该是0，所以下面的结果应该是[0.]\n",
    "        print(sess.run(tf.get_variable(\"v\")))\n",
    "        \n",
    "# 在计算图g2中读取变量\"v\"的取值\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    # 变量初始化\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        # 在计算图g1中，变量\"v\"的取值应该是0，所以下面的结果应该是[0.]\n",
    "        print(sess.run(tf.get_variable(\"v\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上面的代码产生了两个计算图，每个计算图中定义了一个名字为\"v\"的变量。在计算图中g1中，将v初始化为0；在计算图g2中，将v初始化为1。可以看到当运行不同的计算图时，v的变量值也不一样。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow中的计算图不仅仅可以用来隔离张量和计算，它还提供了管理张量和计算的功能。计算图可以用tf.Graph.device函数来指定运行计算的设备。这是TensorFlow使用GPU提供了机制。以下程序可以让加法跑在GPU上。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "g = tf.Graph() # 建立一个新的计算图\n",
    "with g.device('/gpu:0'): # 指定运行的设备\n",
    "    with g.as_default():\n",
    "        a = tf.get_variable(\"a\", shape=[2], initializer=tf.zeros_initializer())\n",
    "        b = tf.get_variable(\"b\", shape=[2], initializer=tf.ones_initializer())\n",
    "        result = a + b;\n",
    "    \n",
    "with tf.Session(graph=g) as sess:\n",
    "    # 变量初始化操作\n",
    "    tf.global_variables_initializer().run()\n",
    "    \n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        # 在计算图g中，获取变量result\n",
    "        print(sess.run(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.constant_initializer()函数的使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fitting shape:\n",
      "[[ 0.  1.  2.  3.]\n",
      " [ 4.  5.  6.  7.]]\n"
     ]
    }
   ],
   "source": [
    "value = [0, 1, 2, 3, 4, 5, 6, 7]\n",
    "# value = np.array(value)\n",
    "# value = value.reshape([2, 4])\n",
    "init = tf.constant_initializer(value)\n",
    "print('fitting shape:')\n",
    "with tf.Session():\n",
    "    x = tf.get_variable('x', shape=[2, 4], initializer=init)\n",
    "    x.initializer.run() # 初始化变量的操作\n",
    "    print(x.eval())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 如果在不同的计算图上定义和使用变量\n",
    "除了使用默认的计算图，Tensorflow支持通过tf.Graph函数来生成新的计算图。不同的计算图上的张量和运算都不会共享.\n",
    "\n",
    "TensorFlow 中的tf.get_variable变量初始化函数:\n",
    "\n",
    "|初始化函数|功能|主要参数|\n",
    "|:---------|:----|:--------|\n",
    "|tf.constant_initializer | 将变量初始化为给定常数 | 常数的取值 |\n",
    "|tf.random_normal_initializer | 将变量初始化为满足正态分布的随机值 | 正态分布的均值和标准差 |\n",
    "|tf.truncated_normal_initializer | 将变量初始化为满足正态分布的随机值，但若随机值偏离平均值超过2个标准差，<br>则这个数会被重新随机 | 正态分布的均值和标准差 |\n",
    "|tf.random_uniform_initializer | 将变量初始化为满足平均分布的随机值 | 最大、最小值\n",
    "|tf.uniform_unit_scaling_initializer | 将变量初始化为满足平均分布但不影响输出数量级的随机值 | factor(产生随机值时乘以的系数) |\n",
    "|tf.zeros_initializer | 将变量初始化为全0 | 无 |\n",
    "|tf.ones_initializer | 将变量初始化为全1 | 无 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.]\n",
      "[ 1.]\n"
     ]
    }
   ],
   "source": [
    "# 建立新图 g1\n",
    "g1 = tf.Graph()\n",
    "with g1.as_default():\n",
    "    # 在新图g1中定义变量'v'，并初始化为0\n",
    "    v = tf.get_variable(\"v\", shape=[1], initializer=tf.zeros_initializer) # initialzer是函数，而不是函数的返回值\n",
    "    \n",
    "# 建立新图 g2\n",
    "g2 = tf.Graph()\n",
    "with g2.as_default():\n",
    "    # 在新图g1中定义变量'v'，并初始化为1\n",
    "    v = tf.get_variable(\"v\", shape=[1], initializer=tf.ones_initializer)\n",
    "    \n",
    "# 在计算图g1中读取变量\"v\"的取值\n",
    "with tf.Session(graph=g1) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        #在计算图g1中，变量“v”的取值应该为0，所以下面会输出[0.]\n",
    "        print(sess.run(tf.get_variable(\"v\")))\n",
    "        \n",
    "# 在计算图g2中读取变量\"v\"的取值\n",
    "with tf.Session(graph=g2) as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    with tf.variable_scope(\"\", reuse=True):\n",
    "        #在计算图g2中，变量“v”的取值应该为1，所以下面会输出[0.]\n",
    "        print(sess.run(tf.get_variable(\"v\")))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在计算图中指定运算设备\n",
    "TensorFlow中的计算图不仅仅可以用来隔离张量和计算。它还提供管理张量和计算的机制。计算图可以通过tf.Graph.device函数来指定运行计算的设备。\n",
    "这里使用cpu(因为笔记本上没有GPU)，下面的计算将跑在CPU上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 22.  28.]\n",
      " [ 49.  64.]]\n"
     ]
    }
   ],
   "source": [
    "g3 = tf.Graph()\n",
    "with g3.as_default():\n",
    "    # 指定运算设备\n",
    "    with g3.device(\"/cpu:0\"):\n",
    "        a = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[2, 3], name='a')\n",
    "        b = tf.constant([1.0, 2.0, 3.0, 4.0, 5.0, 6.0], shape=[3, 2], name='b')\n",
    "        c = tf.matmul(a, b)\n",
    "# Create a session with log_device_placement set to True\n",
    "# 设置log_device_placement=True可以打印出计算操作在哪个设备上完成\n",
    "with tf.Session(graph=g3, config=tf.ConfigProto(log_device_placement=True)) as sess:\n",
    "    print sess.run(c) # 为什么没有打印设备信息呢"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow中维护的集合表\n",
    "有效的管理Tensorflow程序中的资源也是计算图的一个重要功能。在一个计算图中，可以通过集合来管理(collection)来管理不同类型的资源。\n",
    "比如通过`tf.add_to_collection`函数可以加入一个或多个集合中，然后通过`tf.get_collection`获取一个集合里面的所有资源。这里的\n",
    "资源可以是张量、变量或者运行TensorFlow程度所需要的队列资源等等。为了方便使用，TensorFlow也自动管理了一些最常用的集合。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|集合名称\t|集合内容|\t使用场景|\n",
    "|:----------|:--------|:--------|\n",
    "|tf.GraphKeys.VARIABLES\t| 所有变量 | 持久化TensorFlow模型 |\n",
    "|tf.GraphKeys.TRAINABLE_VARIABLES | 可学习的变量(一般指神经网络中的参数) | 模型训练、生成模型可视化内容\n",
    "|tf.GraphKeys.SUMMARIES\t| 日志生成相关的张量 | TensorFlow计算可视化 |\n",
    "|tf.GraphKeys.QUEUE_RUNNERS\t| 处理输入的QueueRunner | 输入处理 |\n",
    "|tf.GraphKeys.MOVING_AVERAGE_VARIABLES\t| 所有计算了滑动平均值的变量\t| 计算变量的滑动平均值 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
