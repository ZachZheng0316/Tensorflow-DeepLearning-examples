{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#双向循环神经网络\" data-toc-modified-id=\"双向循环神经网络-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>双向循环神经网络</a></span></li><li><span><a href=\"#深层循环神经网络\" data-toc-modified-id=\"深层循环神经网络-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>深层循环神经网络</a></span><ul class=\"toc-item\"><li><span><a href=\"#DeepRNN的使用模式\" data-toc-modified-id=\"DeepRNN的使用模式-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>DeepRNN的使用模式</a></span></li></ul></li><li><span><a href=\"#DeepRNN中的Dropout\" data-toc-modified-id=\"DeepRNN中的Dropout-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>DeepRNN中的Dropout</a></span></li><li><span><a href=\"#参考资料\" data-toc-modified-id=\"参考资料-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>参考资料</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 双向循环神经网络\n",
    "\n",
    "双向循环神经网络的结构图如下所示:\n",
    "\n",
    "![Bi_RNN.png](Bi_RNN.png)\n",
    "\n",
    "在有些问题中，当前时刻的输出不仅和之前的状态有关系，也和之后的状态有关系，这就需要双向循环神经网络(bidirectional RNN)来解决这类问题。例如预测一个语句中缺失的单词不仅需要根据前文来判断，也需要根据后文的内容。\n",
    "\n",
    "双向训练神经网络由两个循环神经网络上下堆叠而成，输出由这两个循环神经网络的状态共同决定。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深层循环神经网络\n",
    "\n",
    "深层神经网络(deepRNN)结构如下:\n",
    "    \n",
    "![DeepRNN](DeepRNN.png)\n",
    "\n",
    "DeepRNN是每一时刻将循环体重复多次，这样可以增强表达能力;每一层循环体中的参数是一致的, 而不同层之间的参数可以不一样.\n",
    "\n",
    "TensorFlow提供了MutilRNNCell类来实现DeepRNN的前向传播。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DeepRNN的使用模式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HIDDEN_SIZE = 10       # lstm隐含层的大小\n",
    "number_of_layers = 5 # 深层循环神经网络的层数\n",
    "batch_size = 50      # 截断长度\n",
    "\n",
    "# 定义一个基本的LSTM结构作为循环体的基本结构。\n",
    "# 深层循环神经网络也支持其他循环体结构\n",
    "lstm = tf.nn.rnn_cell.BasicLSTMCell(HIDDEN_SIZE)\n",
    "\n",
    "# 通过MultiRNNCell类实现深层循环神经网络中每一个时刻的前向传播过程\n",
    "# 其中，number_of_layers表示有多少层\n",
    "stacked_lstm = tf.nn.rnn_cell.MultiRNNCell([lstm] * number_of_layers)\n",
    "\n",
    "# 通过zeros_state函数来获取初始状态。\n",
    "# 和经典的循环神经网络一样\n",
    "state = stacked_lstm.zero_state(batch_size=batch_size, tf.float32)\n",
    "\n",
    "# 计算每一时刻前向传播结果\n",
    "# 在训练的过程中为了避免梯度消散的问题，会规定一个最大的序列长度\n",
    "for i in range(len(num_steps)):\n",
    "    # 在第一个时刻声明LSTM结构中使用变量，在之后的时刻都需要复用之前定义好的变量\n",
    "    if i > 0:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    \n",
    "    # 每一步处理时间序列中的一个时刻。\n",
    "    # 将当前输入(current_input)和前一个时刻的(state)传入定义好的LSTM结构\n",
    "    # 得到当前LSTM结构的输出lstm_output和更新后的状态state\n",
    "    stacked_lstm_output, state = stacked_lstm(current_input, state)\n",
    "    \n",
    "    # 将当前时刻LSTM结构的输出传入一个全连接层得到最后的输出\n",
    "    final_output = fully_connected(stacked_lstm_output)\n",
    "    \n",
    "    # 计算当前时刻输出的损失\n",
    "    loss += calc_loss(final_output, expected_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepRNN中的Dropout\n",
    "\n",
    "**使用Dropout的特点**\n",
    "\n",
    "1. 通过dropout可以让CNN和RNN变得更加健壮;\n",
    "2. dropout一般不直接作用在CNN的卷积层, 而是全连接层;\n",
    "3. dropout一般不作用于RNN同一层, 而是不同层之间;\n",
    "\n",
    "在TensorFlow中, 使用tf.nn.rnn_cell.DropoutWrapper类可以很容易实现dropout功能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_size = 10       # 状态向量的维度(也称隐含层的维度)\n",
    "number_of_layers = 5 # 深层循环神经网络的层数\n",
    "batch_size = 5       # batch的大小\n",
    "number_step = 50     # 数据截断长度\n",
    "\n",
    "# 定义LSTM结构\n",
    "lstm = tf.nn.rnn_cell.BasicLSTMCell(lstm_size)\n",
    "\n",
    "# 使用DropoutWrapper类实现dropout功能。\n",
    "# 该类通过两个参数来控制dropout的概率\n",
    "# 一个参数为input_keep_prob，他可以空来控制输入的dropout概率\n",
    "# 另一个为output_keep_prob，它可以用来控制输出的dropout概率\n",
    "dropout_lstm = tf.nn.rnn_cell.DropoutWrapper(lstm, output_keep_prob=0.5)\n",
    "\n",
    "# 在使用了dropout的基础之上定义深层循环神经网络\n",
    "stacked_lstm = tf.nn.rnn_cell.MultiRNNCell([dropout_lstm] * number_of_layers)\n",
    "\n",
    "# 通过zero_state函数来获取初始状态\n",
    "state = stacked_lstm.zero_state(batch_size=batch_size, tf.float32)\n",
    "\n",
    "# 定义损失变量\n",
    "loss = 0\n",
    "\n",
    "# 计算每一个时刻的前向传播结果\n",
    "for i in range(number_step):\n",
    "    # 在第一个时刻声明LSTM结构中使用变量，在之后的时刻都需要复用之前定义好的变量\n",
    "    if i > 0:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "    \n",
    "    # 每一步处理时间序列中的一个时刻。\n",
    "    # 将当前输入(current_input)和前一个时刻的(state)传入定义好的LSTM结构\n",
    "    # 得到当前LSTM结构的输出lstm_output和更新后的状态state\n",
    "    stacked_lstm_output, state = stacked_lstm(current_input, state)\n",
    "    \n",
    "    # 将当前时刻LSTM结构的输出传入一个全连接层得到最后的输出\n",
    "    final_output = fully_connected(stacked_lstm_output)\n",
    "    \n",
    "    # 计算当前时刻输出的损失\n",
    "    loss += calc_loss(final_output, expected_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 参考资料\n",
    "\n",
    "1. 《TensorFlow实战google深度学习框架》"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
