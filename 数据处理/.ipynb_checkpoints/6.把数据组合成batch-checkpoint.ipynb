{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#组合训练数据\" data-toc-modified-id=\"组合训练数据-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>组合训练数据</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 组合训练数据\n",
    "\n",
    "得到单个样例的处理结果之后, 还需要将他们组织成batch, 然后再提供给神经网络的输入层。\n",
    "\n",
    "TensorFlow 提供了以下四个函数来讲单个的样例组织成一个batch形式输出。\n",
    "\n",
    "1. `tf.train.batch()`\n",
    "2. `tf.train.shuffle_batch()`\n",
    "3. `tf.train.batch_join()`\n",
    "4. `tf.train.shuffle_batch_join()`\n",
    "\n",
    "这个四个函数都会生成一个队列, 队列的入队操作是生成单个样例的方法, 而每次出队操作得到是一个batch的样例;其中, 带有`shuffle`的表示要把数据打乱后输出;\n",
    "\n",
    "上述函数除了可以将单个数据整理成输入batch, 也提供了并行化处理输入数据的方法(可以指定多个线程同时进行入队操作). `tf.train.batch` 和 `tf.train.shuffle_bathc`是一致的, 以`tf.train.shuffle`为例, 当指定`num_threads`参数大于1时, 多个线程会同时读取文件中的不同样例进行并行化预处理。\n",
    "\n",
    "如果需要多个线程处理不同文件中的样例时, 可以使用`tf.train.shuffle_batch_join`, 此函数会从文件队列中获取不同的文件分配给不同的线程。\n",
    "\n",
    "一般来说, 输入文件队列是通过`tf.strain.string_input_producer`函数生成, 这个函数会平均分配文件以保证不同文件中数据会被尽量平均使用.\n",
    "\n",
    "**join与非jion函数的区别**\n",
    "\n",
    "`tf.train.shuffle_batch` 和 `tf.train.shuffle_batch_join`函数可以完成多线程并行的方式来进行数据预处理，但是他们各有优劣. 对于`tf.train.shuffle_batch`函数, 不同线程会读取同一个文件, 如果一个文件中的样例比较相似(比如都属于同一个类别), 那么神经网络的训练效果有可能会受到影响. 所以在使用`tf.train.shuffle_batch`函数时, 需要尽量将同一个`TFRecords`文件中的样例随机打乱. 而使用`tf.train.shuffle_batch_join`函数时, 不同的线程会读取不同文件. 如果读取数据的线程总数比总文件数还大, 那么多个线程就会读取同一个文件中相似部分的数据. 而且, 多个线程读取多个文件可能导致过多的硬盘寻址, 从而使得读取速率降低."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 加载库文件\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "\n",
    "# 获取文件列表\n",
    "files = tf.train.match_filenames_once(\"../../../other/test/data.tfrecords-*\")\n",
    "\n",
    "# 创建文件输入队列\n",
    "filename_queue = tf.train.string_input_producer(files, shuffle=False)\n",
    "\n",
    "# 申请一个reader\n",
    "reader = tf.TFRecordReader()\n",
    "\n",
    "# 读取文件中的样例\n",
    "_, serialized_example = reader.read(filename_queue)\n",
    "\n",
    "# 把样例解析为特征\n",
    "\n",
    "feature_i = tf.FixedLenFeature([], tf.int64)\n",
    "feature_j = tf.FixedLenFeature([], tf.int64)\n",
    "feature_map = {'i': feature_i, 'j': feature_j}\n",
    "featues = tf.parse_single_example(serialized_example, features=feature_map)\n",
    "\n",
    "# 提取数据\n",
    "example, label = featues['i'], featues['j']\n",
    "\n",
    "# 设置参数(batch和容量)\n",
    "batch_size = 3\n",
    "capacity = 1000 + 3 * batch_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以下代码展示了 `tf.train.batch()` 的用法."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files:  <tf.Variable 'matching_filenames:0' shape=<unknown> dtype=string_ref>\n",
      "[0 0 0] [0 1 2]\n",
      "[0 0 1] [3 4 0]\n"
     ]
    }
   ],
   "source": [
    "# 使用tf.train.batch函数来组合样例\n",
    "# [example, label]参数给出需要组合的元素\n",
    "# 一般example和label给出了分别代表训练样本和标签\n",
    "# batch_size给出了batch中样例的大小\n",
    "# capacity给出了队列中的最大容量, 当队列长度等于容量时, TensorFlow将暂停入队操作, \n",
    "# 只等待元素出队, 当元素个数小于容量时, TensorFlow将自动重新启动入队操作\n",
    "example_batch, label_batch = tf.train.batch([example, label], batch_size=batch_size, capacity=capacity)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "    \n",
    "    # 打印文件列表\n",
    "    print(\"files: \", files)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    # 获取打印之后的样例;在真实问题中, 这个输出一般会作为神经网路的输入\n",
    "    for i in range(2):\n",
    "        cur_example_batch, cur_label_batch = sess.run([example_batch, label_batch])\n",
    "        print(cur_example_batch, cur_label_batch)\n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "以下代码展示了 `tf.train.shuffle_batch()` 的用法.\n",
    "\n",
    "`tf.train.shuffle_batch` 的用法大部分与 `tf.train.batch` 的用法一致, 但是`min_after_dequeue` 参数是`tf.train.shuffle_batch` 函数特有的。`min_after_dequeu`e参数限制了出队时队列中元素的最少个数。当队列中元素太少时, 随机打乱样例顺序的作用就不大。所以 `tf.train.shuffle_batch`函数提供了限制出队时最少元素个数来保证随机打乱顺序的作用。当出队函数被调用但是队列中元素不够时, 出队操作将等待更多元素入队才会完成。如果 `min_after_dequeue` 参数被设定, `capacity`也应相应调整来满足性能的需求."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "files:  <tf.Variable 'matching_filenames:0' shape=<unknown> dtype=string_ref>\n",
      "[6 0 3] [0 4 4]\n",
      "[3 3 1] [4 1 4]\n"
     ]
    }
   ],
   "source": [
    "example_batch, label_batch = tf.train.shuffle_batch(\n",
    "    [example, label], \n",
    "    batch_size=batch_size, \n",
    "    capacity=capacity, \n",
    "    min_after_dequeue=30)\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])\n",
    "    \n",
    "    # 打印文件列表\n",
    "    print(\"files: \", files)\n",
    "    \n",
    "    coord = tf.train.Coordinator()\n",
    "    threads = tf.train.start_queue_runners(sess=sess, coord=coord)\n",
    "    \n",
    "    # 获取打印之后的样例;在真实问题中, 这个输出一般会作为神经网路的输入\n",
    "    for i in range(2):\n",
    "        cur_example_batch, cur_label_batch = sess.run([example_batch, label_batch])\n",
    "        print(cur_example_batch, cur_label_batch)\n",
    "        \n",
    "    coord.request_stop()\n",
    "    coord.join(threads)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
